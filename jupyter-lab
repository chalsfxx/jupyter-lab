### There are a total of 25 points possible for this final project.   

Your grade will be based on the following Exercises:

Exercise 2 - Create a markdown cell with the title of the notebook. (1 pt)

Exercise 3 - Create a markdown cell for an introduction. (1 pt)

Exercise 4 - Create a markdown cell to list data science languages. (3 pts)

Exercise 5 - Create a markdown cell to list data science libraries. (3 pts)

Exercise 6 - Create a markdown cell with a table of Data Science tools. (3 pts)

Exercise 7 - Create a markdown cell introducing arithmetic expression examples. (1 pt)

Exercise 8 - Create a code cell to multiply and add numbers. (2 pts)

Exercise 9 - Create a code cell to convert minutes to hours. (2 pts)

Exercise 10 -Insert a markdown cell to list Objectives. (3 pts)

Exercise 11 - Create a markdown cell to indicate the Authorâ€™s name. (2 pts)

Exercise 12 - Share your notebook through GitHub (3 pts)

Exercise 13 - Take a screenshot of the first page of the notebook. (1 pt)

The main grading criteria will be:

Is the notebook publicly viewable?

Are there, or do there appear to be, at least 8 Markdown cells and 2 code cells? 

Are the criteria for each cell fulfilled, as described in the "Guidelines for Submission"?

You will not be judged on:

Your English language, including spelling or grammatical mistakes.


### ex2

# Jupyter-lab

### ex3


## This is the introduction of my jupyter lab

### ex4

#### Python: Python is the most widely used language in data science due to its simplicity, readability, and vast ecosystem of libraries such as NumPy, pandas, scikit-learn, TensorFlow, and PyTorch.

#### R: R is another popular language specifically designed for statistical computing and graphics. It has a rich collection of packages for data manipulation, visualization, and statistical analysis.

#### SQL: Although not a programming language per se, SQL (Structured Query Language) is essential for working with relational databases. It allows you to query and manipulate data efficiently.

#### Julia: Julia is a high-level, high-performance language for technical computing. It aims to provide the best of both worlds, combining the ease of use of Python and the speed of languages like C and Fortran.

#### Scala: Scala is a general-purpose programming language that runs on the Java Virtual Machine (JVM). It has gained popularity in the data science community, especially for large-scale data processing using Apache Spark.

#### MATLAB: MATLAB is widely used in academia and industry for numerical computing and prototyping. It offers powerful tools for matrix manipulation, visualization, and algorithm development.

#### SAS: SAS (Statistical Analysis System) is a software suite used for advanced analytics, business intelligence, and data management. It provides a wide range of statistical and data manipulation capabilities.

#### Java: Java is a versatile language with extensive libraries and frameworks. While it may not be as commonly used in data science as Python or R, it is utilized in certain areas such as big data processing and enterprise applications.

#### C/C++: These low-level programming languages are often used for performance-critical tasks in data science, such as developing efficient algorithms or integrating with existing systems.

### ex5

### Popular Data Science Libraries

Here are some widely used data science libraries in Python:

- **NumPy**: A fundamental library for numerical computing in Python, providing powerful data structures and mathematical functions.
- **pandas**: A library for data manipulation and analysis, offering data structures like DataFrames for efficient data handling.
- **scikit-learn**: A comprehensive machine learning library with various algorithms for classification, regression, clustering, and more.
- **TensorFlow**: An open-source library for machine learning and deep learning, widely used for building and training neural networks.
- **PyTorch**: A deep learning framework known for its dynamic computation graph and extensive support for GPU acceleration.
- **Keras**: A high-level neural networks API that runs on top of TensorFlow, enabling quick prototyping and model deployment.
- **matplotlib**: A plotting library for creating static, animated, and interactive visualizations in Python.
- **seaborn**: A statistical data visualization library built on top of matplotlib, providing a higher-level interface and attractive styles.
- **Plotly**: A library for creating interactive visualizations, dashboards, and data-driven web applications.
- **SciPy**: A library for scientific and technical computing, offering modules for optimization, linear algebra, signal processing, and more.
- **statsmodels**: A library for statistical modeling and testing, including regression, time series analysis, and hypothesis testing.
- **NLTK**: The Natural Language Toolkit is a library for working with human language data, providing tools for text processing and analysis.
- **NetworkX**: A library for studying the structure and dynamics of complex networks, with algorithms for graph theory and analysis.

These libraries form the foundation of many data science projects, enabling tasks such as data manipulation, statistical analysis, machine learning, and visualization.


### ex6

### Data Science Tools

| Tool              | Description                                                                                                  |
|-------------------|--------------------------------------------------------------------------------------------------------------|
| Jupyter Notebooks | Interactive computing environment combining code, visualizations, and explanatory text.                      |
| RStudio           | Integrated development environment (IDE) for the R programming language.                                      |
| Anaconda          | Python distribution with pre-installed data science libraries and package management capabilities.           |
| TensorFlow        | Open-source library for machine learning and deep learning, developed by Google.                             |
| scikit-learn      | Machine learning library in Python with a wide range of algorithms and tools.                                |
| PyTorch           | Deep learning framework with a dynamic computation graph and GPU acceleration support.                        |
| Apache Spark      | Distributed computing framework for big data processing and analytics.                                        |
| Tableau           | Data visualization tool for creating interactive dashboards and reports.                                      |
| Power BI          | Business intelligence tool by Microsoft for data visualization and analysis.                                 |
| KNIME             | Open-source platform for data blending, analysis, and modeling with a visual workflow interface.             |
| Apache Hadoop     | Framework for distributed processing of large datasets across clusters of computers.                         |
| RapidMiner        | Data science platform with a visual workflow environment for data preparation and machine learning tasks.    |
| MATLAB            | Proprietary numerical computing environment often used for prototyping and data analysis.                    |
| SAS               | Software suite for advanced analytics, business intelligence, and data management.                            |

This table provides an overview of some popular data science tools used for tasks such as data analysis, machine learning, and visualization. Feel free to explore and experiment with these tools to enhance your data science workflows.


### ex7

### Arithmetic Expression Examples

Arithmetic expressions are mathematical calculations that involve numbers, operators, and sometimes variables. They can be simple or complex, and are commonly used in various programming languages and mathematical contexts. Here are a few examples of arithmetic expressions:

1. Addition: The `+` operator is used for addition. For example, `2 + 3` evaluates to `5`.

2. Subtraction: The `-` operator is used for subtraction. For example, `5 - 2` evaluates to `3`.

3. Multiplication: The `*` operator is used for multiplication. For example, `3 * 4` evaluates to `12`.

4. Division: The `/` operator is used for division. For example, `10 / 2` evaluates to `5`.

5. Exponentiation: The `**` operator is used for exponentiation. For example, `2 ** 3` evaluates to `8` (2 raised to the power of 3).

6. Modulo: The `%` operator calculates the remainder of a division. For example, `10 % 3` evaluates to `1` (remainder of dividing 10 by 3).

These are basic arithmetic operations, but expressions can also involve parentheses `()` to control the order of operations. For example, `(2 + 3) * 4` evaluates to `20` (adding 2 and 3 first, then multiplying the result by 4).

Arithmetic expressions play a crucial role in performing calculations and solving mathematical problems. They are also fundamental in programming for implementing algorithms and manipulating data.


### ex8


```python
# Multiply two numbers
a = 4
b = 3
multiplication_result = a * b
print("Multiplication Result:", multiplication_result)

# Add two numbers
c = 5
d = 2
addition_result = c + d
print("Addition Result:", addition_result)
```

    Multiplication Result: 12
    Addition Result: 7
    

### ex9


```python
# Convert minutes to hours
minutes = 60
hours = minutes / 60

print("Minutes:", minutes)
print("Hours:", hours)

```

    Minutes: 60
    Hours: 1.0
    

### ex10

### Objectives

In this project/task, our main objectives are:

1. **Data Collection**: Gather relevant data from various sources, such as databases, APIs, or files.

2. **Data Preprocessing**: Clean the data by handling missing values, removing duplicates, and addressing any inconsistencies or errors.

3. **Exploratory Data Analysis**: Perform exploratory analysis to gain insights into the data, identify patterns, and understand the relationships between variables.

4. **Feature Engineering**: Create new features or transform existing ones to enhance the predictive power of the data.

5. **Model Development**: Build machine learning models suitable for the problem at hand, considering factors like model selection, hyperparameter tuning, and performance evaluation.

6. **Model Evaluation**: Assess the performance of the developed models using appropriate evaluation metrics and techniques, such as cross-validation or holdout testing.

7. **Model Deployment**: Deploy the selected model into a production environment or prepare it for integration into other systems.

8. **Documentation**: Document the entire process, including data sources, preprocessing steps, model development, and evaluation, to ensure reproducibility and facilitate future iterations.

9. **Presentation and Communication**: Summarize and present the findings, insights, and recommendations in a clear and concise manner, tailored to the target audience.

These objectives outline the key steps and goals of the project/task and provide a roadmap for the data science workflow. It's essential to address each objective to ensure a comprehensive and successful outcome.


### ex11

## Author: Carlos Ferrer Roman

### ex12

### https://github.com/chalsfxx/jupyter-lab/blob/main/jupyter-lab.ipynb

### ex13


```python

```
